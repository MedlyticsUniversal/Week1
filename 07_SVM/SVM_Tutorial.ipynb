{"cells":[{"cell_type":"markdown","metadata":{"id":"q71qY1utlDUm","colab_type":"text","cell_id":"baf778cd2c2843cc80760074f9b3a775","deepnote_cell_type":"markdown"},"source":"# Support Vector Machine (SVM) Tutorial","block_group":"00000-eb16b0eb-b205-4981-9ce2-b30451097902"},{"cell_type":"markdown","metadata":{"id":"EgDMEbcOxfzU","colab_type":"text","cell_id":"e5bb139e3d524c10916ec4a584b18d5f","deepnote_cell_type":"markdown"},"source":"SVMs are algorithms that can be used for both classification and regression purposes, although they are more commonly used for **classification**.\n\nTo understand how SVMs work, imagine each observation is a point in $n$-dimensional space, where $n$ is the total number of features.\n\nAn SVM classifies data by finding the **optimal hyperplane** that best divides the data into groups by class. In a 2D space (data with two features), this \"hyperplane\" is a line dividing the space into two regions, as shown below. The trick to finding the optimal line is maximizing the distance from the line to any data point. This is the **maximum margin**.\n\n![svm_hyperplane.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/svm_hyperplane.png)\n\n**Support vectors** are the data points nearest to the hyperplane. If these points were removed, the optimal hyperplane would change. The position and number of points outside the support vectors will not change the hyperplane fit at all. This means SVMs can have solid results on **small datasets** (with valuable support vectors). In the image below, the support vectors have been circled.\n\n![svm4.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/svm4.png)","block_group":"00001-12f6a78e-7817-4cc9-8ed7-ccb4b9a93716"},{"cell_type":"markdown","metadata":{"id":"-0-2PaniEWk9","colab_type":"text","cell_id":"a55a96267be340c9936abf35b6b6cd94","deepnote_cell_type":"markdown"},"source":"Intuitively, the further from the hyperplane our support vectors points lie, the larger the margin and the more confident we are in our classifier. Therefore, we ideally want our data points to be as far away from the hyperplane as possible while still being on the correct side.","block_group":"00002-ca7ee2ba-204a-4ca3-a8f7-b45ee8f3705b"},{"cell_type":"markdown","metadata":{"id":"Lh0EH1TzEWlA","colab_type":"text","cell_id":"694d94226135432d8b188ba7d035f4cb","deepnote_cell_type":"markdown"},"source":"So what happens when data overlaps, or doesn't have a clear line of division? Take this graph as an example:\n\n![svm1.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/svm1.png)\n\nHere we have two options:\n**1)** Try to draw a line despite some points being on the wrong side:\n\n![svm2.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/svm2.png)\n\nOr **2)** give up on having a straight line, and define a curved or segmented line instead:\n\n![svm3.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/svm3.png)\n\nBoth options can work! However, there are tradeoffs. In some cases, the first option may not be accurate enough. Alternatively, the second option may take too long for large datasets and may overfit to the training data.","block_group":"00003-c1c1d41d-90c3-46cb-b1fb-a191da904d3b"},{"cell_type":"markdown","metadata":{"id":"vfvZCdtTla0p","colab_type":"text","cell_id":"8d116b8bc69543daa1e4a719ace5509a","deepnote_cell_type":"markdown"},"source":"## Important Parameters for SVM\n\nIn this notebook, we will be using sklearn's `SVC` (Support Vector Classifier documentation found here: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\nFeel free to look at the other available SVM models here: https://scikit-learn.org/stable/modules/svm.html.\n\nIn this section, we will describe 3 key parameters for training SVMs: Regularization, Gamma, and Kernel.","block_group":"00004-d4b2438e-43ef-4454-9a46-e139b9f9bc79"},{"cell_type":"markdown","metadata":{"id":"8fVGb0z6EWlC","colab_type":"text","cell_id":"95688d7cf3874e448b0db4d4be4550e8","deepnote_cell_type":"markdown"},"source":"### Regularization (C)\n---\n\n**Regularization** parameter, also called degrees of tolerance and denoted as \"C\", impacts the division of data by telling the SVM optimization how much you want to avoid misclassifying the training data.\n\n- **Low** regularization values create smooth decision boundaries\n- **High** regularization values create more complex decision boundaries but may overfit to the training set\n\n**Low C:**\n\n![svm2.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/svm2.png)\n\n**High C:**\n\n![svm3.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/svm3.png)","block_group":"00005-505366a7-20e6-4a04-bc40-f81d19588823"},{"cell_type":"markdown","metadata":{"cell_id":"122a58842f7c4444b10ef9be9673557c","deepnote_cell_type":"markdown"},"source":"Here's a bunch of **C** values (in increasing order) to compare:\n![c_values.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/c_values.png)","block_group":"5bc3772b7b2949a89f45fb78f60f5464"},{"cell_type":"markdown","metadata":{"id":"XFzIqLy0EWlE","colab_type":"text","cell_id":"cf46e0c972154e0dadc834a24d5026c9","deepnote_cell_type":"markdown"},"source":"### Gamma\n---\n\n**Gamma** defines how close a training data point needs to be to the potential line of separation to impact the final decision boundary. High gamma values can lead to a lot of the data not being considered.\n\n![high_gamma.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/high_gamma.png)\n![low_gamma.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/low_gamma.png)","block_group":"00006-a00040ad-cabc-4e29-a669-8e4c7f07e5e7"},{"cell_type":"markdown","metadata":{"id":"We-EM7x-EWlF","colab_type":"text","cell_id":"3631f3be1af441c2a7f00e6fd37e588d","deepnote_cell_type":"markdown"},"source":"### Kernel\n---\n\nA **kernel** is essentially a transformation that makes decision boundaries possible for differently shaped distributions. In the example below, it is impossible to draw a straight line to separate the circles from the squares.\n\n![kernel1.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/kernel1.png)\n\nHowever, if we apply a kernel to transform the data into 3D space (for example, with $z = x^2 + y^2$), we may be able to draw a line on the Z-X or Z-Y plane.\n\n![kernel2.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/kernel2.png)\n\nLooking at it again in X-Y, we have managed to separate the data quite well.\n\n![kernel3.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/kernel3.png)","block_group":"00007-0abb1ecf-69e1-45e3-a4f6-b03b4e0650e2"},{"cell_type":"markdown","metadata":{"cell_id":"97a4582eb1374abfa2b65ce7b3cea218","deepnote_cell_type":"markdown"},"source":"Here, notice how different kernels allow sklearn's `SVC` to fit to different types of data (the bottom-right value is the accuracy; for each of the 3 distributions, some kernels will work very well and others will be pretty lackluster):\n![many_kernels.png](https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Images/many_kernels.png)","block_group":"bc86c26a6f5a4b10a228693bfa061524"},{"cell_type":"markdown","metadata":{"id":"L0bM5mvsEWlK","colab_type":"text","cell_id":"b23796c5eede40d89bab077967c3466e","deepnote_cell_type":"markdown"},"source":"# Example SVM\n\nAs an example, we'll use an SVM to predict diabetes using the Pima Diabetes dataset. Load and view this data in the cells below:","block_group":"00008-e17ab439-518e-427c-bf07-c7897e1019c1"},{"cell_type":"code","metadata":{"id":"m_GGUYGvEWlL","colab":{},"colab_type":"code","source_hash":null,"execution_start":1694735328366,"execution_millis":1711,"deepnote_to_be_reexecuted":false,"cell_id":"1451084f92224c1a922988a95bc50e79","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC","block_group":"00009-873a660f-adda-4bb8-9f6f-e19c2bc52274","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HOyMSQyqEWlR","colab_type":"text","cell_id":"083611f204844033a25a9d65b632686d","deepnote_cell_type":"markdown"},"source":"## Loading the Data","block_group":"00010-af1ffaa5-9d9d-4a3f-ad86-f636c7234078"},{"cell_type":"code","metadata":{"id":"t9-qgexhEWlS","colab":{},"colab_type":"code","source_hash":null,"execution_start":1694735345319,"execution_millis":404,"deepnote_to_be_reexecuted":false,"cell_id":"cdef6d07d57b4ce4af922316c3f2d277","deepnote_cell_type":"code"},"source":"url = \"https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Week1/diabetes.csv\"\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndata = pd.read_csv(url, names=names)\n\n# Dropping NaN rows\ninvalid = ['plas', 'pres', 'skin', 'test', 'mass']\n\nfor i in invalid:\n    data[i].replace(to_replace=0, value=np.nan, inplace=True)\n    \ndata = data.dropna(axis=0).reset_index(drop=True)\n\ndata.head()","block_group":"00011-b973e06f-57d8-4d1d-8a82-39352d976e0e","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":9,"row_count":5,"columns":[{"name":"preg","dtype":"int64","stats":{"unique_count":4,"nan_count":0,"min":"0","max":"3","histogram":[{"bin_start":0,"bin_end":0.3,"count":1},{"bin_start":0.3,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.8999999999999999,"count":0},{"bin_start":0.8999999999999999,"bin_end":1.2,"count":2},{"bin_start":1.2,"bin_end":1.5,"count":0},{"bin_start":1.5,"bin_end":1.7999999999999998,"count":0},{"bin_start":1.7999999999999998,"bin_end":2.1,"count":1},{"bin_start":2.1,"bin_end":2.4,"count":0},{"bin_start":2.4,"bin_end":2.6999999999999997,"count":0},{"bin_start":2.6999999999999997,"bin_end":3,"count":1}]}},{"name":"plas","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"78.0","max":"197.0","histogram":[{"bin_start":78,"bin_end":89.9,"count":2},{"bin_start":89.9,"bin_end":101.8,"count":0},{"bin_start":101.8,"bin_end":113.7,"count":0},{"bin_start":113.7,"bin_end":125.6,"count":0},{"bin_start":125.6,"bin_end":137.5,"count":1},{"bin_start":137.5,"bin_end":149.4,"count":0},{"bin_start":149.4,"bin_end":161.3,"count":0},{"bin_start":161.3,"bin_end":173.2,"count":0},{"bin_start":173.2,"bin_end":185.10000000000002,"count":0},{"bin_start":185.10000000000002,"bin_end":197,"count":2}]}},{"name":"pres","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"40.0","max":"70.0","histogram":[{"bin_start":40,"bin_end":43,"count":1},{"bin_start":43,"bin_end":46,"count":0},{"bin_start":46,"bin_end":49,"count":0},{"bin_start":49,"bin_end":52,"count":1},{"bin_start":52,"bin_end":55,"count":0},{"bin_start":55,"bin_end":58,"count":0},{"bin_start":58,"bin_end":61,"count":1},{"bin_start":61,"bin_end":64,"count":0},{"bin_start":64,"bin_end":67,"count":1},{"bin_start":67,"bin_end":70,"count":1}]}},{"name":"skin","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"23.0","max":"45.0","histogram":[{"bin_start":23,"bin_end":25.2,"count":2},{"bin_start":25.2,"bin_end":27.4,"count":0},{"bin_start":27.4,"bin_end":29.6,"count":0},{"bin_start":29.6,"bin_end":31.8,"count":0},{"bin_start":31.8,"bin_end":34,"count":1},{"bin_start":34,"bin_end":36.2,"count":1},{"bin_start":36.2,"bin_end":38.400000000000006,"count":0},{"bin_start":38.400000000000006,"bin_end":40.6,"count":0},{"bin_start":40.6,"bin_end":42.8,"count":0},{"bin_start":42.8,"bin_end":45,"count":1}]}},{"name":"test","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"88.0","max":"846.0","histogram":[{"bin_start":88,"bin_end":163.8,"count":2},{"bin_start":163.8,"bin_end":239.6,"count":1},{"bin_start":239.6,"bin_end":315.4,"count":0},{"bin_start":315.4,"bin_end":391.2,"count":0},{"bin_start":391.2,"bin_end":467,"count":0},{"bin_start":467,"bin_end":542.8,"count":0},{"bin_start":542.8,"bin_end":618.6,"count":1},{"bin_start":618.6,"bin_end":694.4,"count":0},{"bin_start":694.4,"bin_end":770.1999999999999,"count":0},{"bin_start":770.1999999999999,"bin_end":846,"count":1}]}},{"name":"mass","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"28.1","max":"43.1","histogram":[{"bin_start":28.1,"bin_end":29.6,"count":1},{"bin_start":29.6,"bin_end":31.1,"count":3},{"bin_start":31.1,"bin_end":32.6,"count":0},{"bin_start":32.6,"bin_end":34.1,"count":0},{"bin_start":34.1,"bin_end":35.6,"count":0},{"bin_start":35.6,"bin_end":37.1,"count":0},{"bin_start":37.1,"bin_end":38.6,"count":0},{"bin_start":38.6,"bin_end":40.1,"count":0},{"bin_start":40.1,"bin_end":41.6,"count":0},{"bin_start":41.6,"bin_end":43.1,"count":1}]}},{"name":"pedi","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"0.158","max":"2.288","histogram":[{"bin_start":0.158,"bin_end":0.371,"count":3},{"bin_start":0.371,"bin_end":0.584,"count":1},{"bin_start":0.584,"bin_end":0.797,"count":0},{"bin_start":0.797,"bin_end":1.01,"count":0},{"bin_start":1.01,"bin_end":1.2229999999999999,"count":0},{"bin_start":1.2229999999999999,"bin_end":1.436,"count":0},{"bin_start":1.436,"bin_end":1.6489999999999998,"count":0},{"bin_start":1.6489999999999998,"bin_end":1.8619999999999999,"count":0},{"bin_start":1.8619999999999999,"bin_end":2.075,"count":0},{"bin_start":2.075,"bin_end":2.288,"count":1}]}},{"name":"age","dtype":"int64","stats":{"unique_count":5,"nan_count":0,"min":"21","max":"59","histogram":[{"bin_start":21,"bin_end":24.8,"count":1},{"bin_start":24.8,"bin_end":28.6,"count":1},{"bin_start":28.6,"bin_end":32.4,"count":0},{"bin_start":32.4,"bin_end":36.2,"count":1},{"bin_start":36.2,"bin_end":40,"count":0},{"bin_start":40,"bin_end":43.8,"count":0},{"bin_start":43.8,"bin_end":47.599999999999994,"count":0},{"bin_start":47.599999999999994,"bin_end":51.4,"count":0},{"bin_start":51.4,"bin_end":55.199999999999996,"count":1},{"bin_start":55.199999999999996,"bin_end":59,"count":1}]}},{"name":"class","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":4}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"preg":1,"plas":89,"pres":66,"skin":23,"test":94,"mass":28.1,"pedi":0.167,"age":21,"class":0,"_deepnote_index_column":0},{"preg":0,"plas":137,"pres":40,"skin":35,"test":168,"mass":43.1,"pedi":2.288,"age":33,"class":1,"_deepnote_index_column":1},{"preg":3,"plas":78,"pres":50,"skin":32,"test":88,"mass":31,"pedi":0.248,"age":26,"class":1,"_deepnote_index_column":2},{"preg":2,"plas":197,"pres":70,"skin":45,"test":543,"mass":30.5,"pedi":0.158,"age":53,"class":1,"_deepnote_index_column":3},{"preg":1,"plas":189,"pres":60,"skin":23,"test":846,"mass":30.1,"pedi":0.398,"age":59,"class":1,"_deepnote_index_column":4}]},"text/plain":"   preg   plas  pres  skin   test  mass   pedi  age  class\n0     1   89.0  66.0  23.0   94.0  28.1  0.167   21      0\n1     0  137.0  40.0  35.0  168.0  43.1  2.288   33      1\n2     3   78.0  50.0  32.0   88.0  31.0  0.248   26      1\n3     2  197.0  70.0  45.0  543.0  30.5  0.158   53      1\n4     1  189.0  60.0  23.0  846.0  30.1  0.398   59      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preg</th>\n      <th>plas</th>\n      <th>pres</th>\n      <th>skin</th>\n      <th>test</th>\n      <th>mass</th>\n      <th>pedi</th>\n      <th>age</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>89.0</td>\n      <td>66.0</td>\n      <td>23.0</td>\n      <td>94.0</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>137.0</td>\n      <td>40.0</td>\n      <td>35.0</td>\n      <td>168.0</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>78.0</td>\n      <td>50.0</td>\n      <td>32.0</td>\n      <td>88.0</td>\n      <td>31.0</td>\n      <td>0.248</td>\n      <td>26</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>197.0</td>\n      <td>70.0</td>\n      <td>45.0</td>\n      <td>543.0</td>\n      <td>30.5</td>\n      <td>0.158</td>\n      <td>53</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>189.0</td>\n      <td>60.0</td>\n      <td>23.0</td>\n      <td>846.0</td>\n      <td>30.1</td>\n      <td>0.398</td>\n      <td>59</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"00EMh2hBEWlc","colab_type":"text","cell_id":"dad7bb6afce34dbba84f26b8319920a4","deepnote_cell_type":"markdown"},"source":"## Splitting Data into Training, Validation, and Testing Sets","block_group":"00012-5384c523-24c7-4e44-8511-7c188708fb47"},{"cell_type":"code","metadata":{"id":"fBtdMz_vEWld","colab":{},"colab_type":"code","source_hash":null,"execution_start":1694735468443,"execution_millis":5,"deepnote_to_be_reexecuted":false,"cell_id":"e6f66b7d4c574a72afbb63a99c4ef9f7","deepnote_cell_type":"code"},"source":"X_cols = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n\ny_col = 'class'\n\ntest_size = 0.2\nX_train, X_test, y_train, y_test = train_test_split(data[X_cols], data[y_col], test_size=test_size, random_state=0)\n\n# Further split X and y of training into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0)","block_group":"00013-7f657106-3e82-4c47-bfa5-5d28fb74be4f","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HBR277yFEWli","colab_type":"text","cell_id":"a0cd722196054404b97ef03815d78409","deepnote_cell_type":"markdown"},"source":"## Building the Model\nNext, we create an SVC model, and fit the data.","block_group":"00014-dd549bb2-e0e8-4cfa-a751-ef726d18d518"},{"cell_type":"code","metadata":{"id":"pW-Ac5pQEWll","colab":{"height":92,"base_uri":"https://localhost:8080/"},"outputId":"dad5e52b-84a1-40a2-cd7e-7cbdb6d96564","colab_type":"code","source_hash":null,"execution_start":1694735534931,"execution_millis":103,"deepnote_to_be_reexecuted":false,"cell_id":"0e900f1a1fdb48f8b30dc727b689cc32","deepnote_cell_type":"code"},"source":"# Creating a model with sklearn's SVC\nsvm = SVC(gamma=.1, C=1)\n\n# Training/fitting a model with training data\nsvm.fit(X_train, y_train)","block_group":"00015-73467eb6-5ba4-437f-85db-f6d3a499fd64","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"SVC(C=1, gamma=0.1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=0.1)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"1DnG36VMEWlq","colab_type":"text","cell_id":"6ebfbbcf57fe41e6b2975d0cb9171c59","deepnote_cell_type":"markdown"},"source":"## Evaluation","block_group":"00016-799ecaa9-3a78-4066-a39a-31fe7a20a05d"},{"cell_type":"code","metadata":{"id":"hPkcLqS_EWlr","colab":{"height":55,"base_uri":"https://localhost:8080/"},"outputId":"f59b6a20-761b-4af7-eba5-fd3044534526","colab_type":"code","source_hash":null,"execution_start":1694735550503,"execution_millis":17,"deepnote_to_be_reexecuted":false,"cell_id":"5e8d271d3d2b4d958826945406dc8e0f","deepnote_cell_type":"code"},"source":"# Printing accuracy of training and validation data\ny_train_pred=svm.predict(X_train)\nprint(\"Training Accuracy is\", accuracy_score(y_train, y_train_pred)*100)\ny_val_pred=svm.predict(X_val)\nprint(\"Validation Accuracy is\", accuracy_score(y_val,y_val_pred)*100)","block_group":"00017-51e4ea9b-a481-4a19-aed4-4b38d2e6bd54","execution_count":null,"outputs":[{"name":"stdout","text":"Training Accuracy is 100.0\nValidation Accuracy is 63.49206349206349\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"POLOa6NAEWlu","colab_type":"text","cell_id":"deceba95a4aa4638a0f1c0e4dce31071","deepnote_cell_type":"markdown"},"source":"As you can see above, despite achieving a training accuracy of 100%, the validation accuracy is only 63%. This suggests that the model has **overfit**! In general, if your training accuracy reaches 100%, your model has most likely overfit to your training data.\n\nPlay around with the parameters and try to balance out the training and validation accuracies. You can start with the ones we've mentioned above, but look through sklearn's documentation for more options!","block_group":"00018-ac475caa-d0dc-4a34-b273-d97dd40e24c0"},{"cell_type":"markdown","metadata":{"id":"Cjb0uy-jEWlv","colab_type":"text","cell_id":"bcd9545bf3d045f7b95f248f253a6460","deepnote_cell_type":"markdown"},"source":"Once you feel like your model is at a good place, you can do one last evaluation using the **testing data**. Don't forget, your testing data should never be used to change your model and is reserved for one final evaluation.","block_group":"00019-cfd8f4d1-2533-402a-a6d8-7753e0ddd909"},{"cell_type":"code","metadata":{"id":"RmyJg3jvEWlw","colab":{"height":73,"base_uri":"https://localhost:8080/"},"outputId":"c5cb3fa0-5f2f-4c36-cd2e-9e9f90e8fe21","colab_type":"code","source_hash":null,"execution_start":1694735646539,"execution_millis":15,"deepnote_to_be_reexecuted":false,"cell_id":"f339f3ba03404b66a2a876c13c0d2ed8","deepnote_cell_type":"code"},"source":"y_test_pred=svm.predict(X_test)\n\nprint(\"Training Accuracy is\", accuracy_score(y_train, y_train_pred)*100)\nprint(\"Validation Accuracy is\", accuracy_score(y_val,y_val_pred)*100)\nprint(\"Testing Accuracy is\", accuracy_score(y_test,y_test_pred)*100)","block_group":"00020-bc479e53-4618-4b3c-a072-6a431524bcc7","execution_count":null,"outputs":[{"name":"stdout","text":"Training Accuracy is 100.0\nValidation Accuracy is 63.49206349206349\nTesting Accuracy is 68.35443037974683\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"YmfXxVxgEWl0","colab_type":"text","cell_id":"386730bfb578436ea5ccd04d67c0cd85","deepnote_cell_type":"markdown"},"source":"# Conclusion\n**Pros of SVM**\n- SVM works well with small datasets with many attributes (high-dimensional)\n- SVM models run fast and don't use much memory as they only depend on a few support vectors\n\n**Cons of SVM**\n- Training takes a long time, which isn't well suited for larger datasets\n- SVM is less effective on \"noisier\" datasets with overlapping classes\n- Results are very dependent on parameters, which can be hard to tune on small datasets\n    --> SVMs do poorly when number of features exceeds number of training data samples","block_group":"00021-adc8619e-6019-459a-bde4-dd2b57333e73"},{"cell_type":"markdown","metadata":{"id":"oOiqnNAbEWl2","colab_type":"text","cell_id":"c1c881a687d64c39b4d0b1260ce53247","deepnote_cell_type":"markdown"},"source":"## Resource\n\n_Parts of this lesson are adapted from https://medium.com/machine-learning-101._\n> This is a great series of articles on introductory machine learning. Take a look if you feel like you need additional clarification.","block_group":"00022-b020f21b-8096-4746-bdf2-6c7e947a7fc5"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=67231ff1-13ba-4f0b-99c2-0fe76b4d3844' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM_Tutorial","provenance":[],"collapsed_sections":[]},"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"d9310f760df046d4b5db9bfe0ca1a6a5","deepnote_execution_queue":[],"deepnote_persisted_session":{"createdAt":"2023-09-15T00:16:45.512Z"}}}